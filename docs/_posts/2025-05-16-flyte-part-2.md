---
layout: default
title: "The Simplest Solution Is Best: Correcting Playlist Rot with Flyte and Kubernetes (Part 2)"
date: "2025/05/16"
publish: true
---

> Full source code for the latest iteration of this project is [here](https://github.com/mikepartelow/homeslice/tree/main/apps/remedy-tidal) and [here](https://github.com/mikepartelow/homeslice/tree/main/pulumi/flyte).

## Re-Introduction

In [Part 0]({% post_url 2025-05-10-flyte-part-0 %}) I described the design for a The system using the [Flyte](http://flyte.org) workflow orchestration system to find `unavailable` tracks in a [Tidal](http://tidal.com) playlist, select suitable replacement tracks, and publish a corrected playlist. 

In [Part 1]({% post_url 2025-05-11-flyte-part-1 %}) I added Secrets management to the system, and fleshed out my Makefile to make development easier.

So far I've been running the workflow on my laptop, with a few parts stubbed out. Now it's time to complete the workflow, stand up Flyte in my local Kubernetes cluster, and run the workflow end-to-end in Kubernetes!

## Completing the workflow

With most of the tasks stubbed in a previous iteration, completing the workflow was a straightforward task of replacing the stubs with working code.

The Task code is simple and clean, since Flyte manages mounting the auth secrets into the Task pod, and the Tidal auth is handled by my own library. The Task for finding a replacement for an unavailable track is just two lines long, excluding boilerplate and logging:


```python
@fl.task(
    container_image=image_spec.DEFAULT,
    secret_requests=[
        fl.Secret(
            group=secrets.TIDAL_CREDS_GROUP,
            key=secrets.TIDAL_CREDS_KEY,
            mount_requirement=fl.Secret.MountType.FILE,
        )
    ],
    cache=True,
    cache_version="v5",
)
def find_new_track(old_track: model.Track, path_to_creds: str) -> model.Track | None:
    """Find a reasonable replacement for the given track."""
    logging.debug("path_to_creds: %s", path_to_creds)
    session = auth.login(path_to_creds)
    return track.find(session, old_track)
```

When no replacement track is found, `track.find()` returns `None`. We use another Task to filter out the `None`s. 

```python
@fl.task(
    container_image=image_spec.DEFAULT,
    cache=True,
    cache_version="v5",
)
def filter_nones(tracks: list[model.Track | None]) -> list[model.Track]:
    """Return the given list of tracks with any None elements removed."""
    return [t for t in tracks if t is not None]
```

Why not just use the same list comprehension in the workflow itself? Because in the context of the workflow, we're dealing with [Promises](https://en.wikipedia.org/wiki/Futures_and_promises) that have not yet been materialized. The result value is not yet present, so a list comprehension inside the workflow wouldn't be able to determine which ones are `None`. Passing the list of `find_new_track()` results to another task materializes the Promise values and allows us to use a simple list comprehension

ğŸ‘‰ Key point: Flyte `Tasks` are plain old Python code. Flyte `Workflows` are a Python-like [DSL](https://en.wikipedia.org/wiki/Domain-specific_language) where the inputs and outputs of called `Tasks` are Promises, the values of which can't be acted upon inside the Workflow.

Speaking of the workflow, here's the final version:

```python
l.workflow
def remedy_tidal_wf(
    playlist_id: str,
    new_playlist_name: str,
    path_to_creds: str = secrets.TIDAL_CREDS_PATH,
) -> str:
    """Remedy a Tidal playlist. Publish remedied tracks to new_playlist_name and return its id.
    Tidal tracks can become unavailable. This workflow finds those tracks and publishes reasonable
    alternatives to a new playlist.
    """
    core.logging.init()

    logging.info("remedy tidal wf(%s, %s, %s)", playlist_id, new_playlist_name, path_to_creds)

    playlist = tasks.fetch_playlist(playlist_id, path_to_creds)

    unavailable = tasks.filter_unavailable(playlist)

    partial_task = functools.partial(tasks.find_new_track, path_to_creds=path_to_creds)

    new_tracks = fl.map_task(partial_task)(old_track=unavailable)

    remedied = tasks.filter_nones(new_tracks)

    new_playlist_id = tasks.publish_playlist(remedied, new_playlist_name, path_to_creds)

    return new_playlist_id
```

Note the two `filter` tasks we call, instead of using list comprehensions or Python's builtin `filter` function.

The final Task, `publish_playlist()`, is the only part of this workflow with a [Side Effect](https://en.wikipedia.org/wiki/Side_effect_(computer_science)): it creates or updates a Tidal playlist.

For a "real" workflow it might be a better design to return a JSON representation of the new Playlist and have some non-Flyte code publish the playlist. The side effects are not verified in this workflow (they're verified when I manually inspect the new playlist), so Flyte can't know if it needs to re-run the final task.

Here's the publish Task. It's nothing fancy!

```python
@fl.task(
    container_image=image_spec.DEFAULT,
    secret_requests=[
        fl.Secret(
            group=secrets.TIDAL_CREDS_GROUP,
            key=secrets.TIDAL_CREDS_KEY,
            mount_requirement=fl.Secret.MountType.FILE,
        )
    ],
)
def publish_playlist(tracks: list[model.Track], new_playlist_name: str, path_to_creds: str) -> str:
    """Publish a Tidal playlist. Create a new playlist if needed. Return playlist id."""
    session = auth.login(path_to_creds)

    new_playlist = None
    for candidate in session.user.playlists():
        if candidate.name == new_playlist_name:
            new_playlist = candidate
            break

    if not new_playlist:
        new_playlist = session.user.create_playlist(new_playlist_name, new_playlist_name)

    track_ids = [t.id for t in tracks]

    max_add = min(100, len(track_ids))
    start, finish = 0, max_add
    while finish <= len(track_ids):
        new_playlist.add(track_ids[start:finish])
        start, finish = finish, finish + max_add

    return new_playlist.id
```

The only interesting bit in this code is the loop for adding tracks to the playlist. We chunk the playlist additions to avoid hitting maximum API limits. When creating larger playlists it's necessary to rate limit ourselves, but in this case, we're adding tens of tracks and the rate limit is not necessary.

This code could be improved with automatic rate limiting and error handling when adding tracks. In both cases we currently allow exceptions to interrupt the `publish_playlist()` track and fail the Flyte workflow. That's fine for this use case!

### Tests

Flyte tasks are just regular Python functions, written in a functional style that makes testing easy. In my codebase, the easiest tasks to test are the filters, which are just one-line list comprehensions. The other tasks interact with an external service. Since I was optimizing for project completion, and since this code is already working well in other contexts, I focused on testing the track scoring algorithm.

```python
def test_track_score():
    assert track.score(
        model.Track(id=1, name="foo", artist="bar", album="baz",),
        model.Track(id=2, name="zip", artist="zap", album="zorp")
    ) == 0

    assert track.score(
        model.Track(id=1, name="foo", artist="bar", album="baz",),
        model.Track(id=2, name="foo", artist="zap", album="zorp")
    ) == 10

    assert track.score(
        model.Track(id=1, name="foo", artist="bar", album="baz",),
        model.Track(id=2, name="foo", artist="bar", album="zorp")
    ) == 20

    assert track.score(
        model.Track(id=1, name="foo", artist="bar", album="baz",),
        model.Track(id=2, name="foo", artist="bar", album="baz")
    ) == 30
```

Pretty simple, and it lays the groundwork for improving half of the code that actually matters in my workflow (the other half being the scrubber). 

### Flyte Console

http://localhost:30080/console/projects/remedy-tidal/domains/development/executions

### Wrapping up the code

With a couple unit tests and several successful runs in the local Flyte sandbox to convince me it works reasonably well, it was time to move on to standing up Flyte in my home Kubernetes cluster.

## Standing up Flyte

## Running the workflow on Kubernetes
